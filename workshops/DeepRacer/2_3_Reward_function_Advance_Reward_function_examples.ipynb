{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. AWS DeepRacer Reward Function Examples - Advanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on experiences of people at various different AWS DeepRacer events across the globe, we have collated a set of advanced Rewward functions which could help you achieve faster times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Source- [Github- scottpletcher/deepracer](https://github.com/scottpletcher/deepracer)__\n",
    "\n",
    "Selecting the top reward functions by the author. You can learn more by clicking on the link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__PurePursuit__\n",
    "\n",
    "Based on an acedemic paper from 1992 by R. Craig Coulter titled \"Implementation of the Pure Pursuit Tracking Algorithm\".\n",
    "\n",
    "When we drive a real car, we don't look out the side window and ensure we're a distance from the side of the road rather, we identify a point down the road and use that to orient ourselves.\n",
    "\n",
    "All the hyperparameters were set to default and training period was for about 4 hours\n",
    "\n",
    "__Note__: this function is not an exact replica of the one stated at the source as the parameter listing have changed over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function(params):\n",
    "    \n",
    "    import math\n",
    "    \n",
    "    reward = 1e-3\n",
    "        \n",
    "    rabbit = [0,0]\n",
    "    pointing = [0,0]\n",
    "    \n",
    "    # Read input variables\n",
    "    waypoints = params['waypoints']\n",
    "    closest_waypoints = params['closest_waypoints']\n",
    "    heading = params['heading']\n",
    "    x=params['x']\n",
    "    y=params['y']\n",
    "    # Reward when yaw (car_orientation) is pointed to the next waypoint IN FRONT.\n",
    "    \n",
    "    # Find nearest waypoint coordinates\n",
    "    rabbit = waypoints[closest_waypoints[1]]\n",
    "    \n",
    "    radius = math.hypot(x - rabbit[0], y - rabbit[1])\n",
    "    \n",
    "    pointing[0] = x + (radius * math.cos(heading))\n",
    "    pointing[1] = y + (radius * math.sin(heading))\n",
    "    \n",
    "    vector_delta = math.hypot(pointing[0] - rabbit[0], pointing[1] - rabbit[1])\n",
    "    \n",
    "    # Max distance for pointing away will be the radius * 2\n",
    "    # Min distance means we are pointing directly at the next waypoint\n",
    "    # We can setup a reward that is a ratio to this max.\n",
    "        \n",
    "    if vector_delta == 0:\n",
    "        reward += 1\n",
    "    else:\n",
    "        reward += ( 1 - ( vector_delta / (radius * 2)))\n",
    "\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__SelfMotivator__\n",
    "\n",
    "_With supervised learning, your model will only be as good as the ground truth you have to give it. With reinforcement learning, the model has the potential to become better than anything or anyone has ever done that thing._\n",
    "\n",
    "Trust in the reinforcement learning process to figure out the best way around the track.<br>\n",
    "The author decided to create a simple function that simply motivated the model to stay on the track and get around in as few steps as possible. \n",
    "\n",
    "Trained for about 3 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function(params):\n",
    "\n",
    "    if params[\"all_wheels_on_track\"] and params[\"steps\"] > 0:\n",
    "        reward = ((params[\"progress\"] / params[\"steps\"]) * 100) + (params[\"speed\"]**2)\n",
    "    else:\n",
    "        reward = 0.01\n",
    "        \n",
    "    return float(reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Source- [Medium- beSharp](https://medium.com/proud2becloud/deepracer-our-journey-to-the-top-ten-257ff69922e)__\n",
    "\n",
    "Selecting the top reward functions by the author. You can learn more by clicking on the link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def reward_function(params):\n",
    "    \n",
    "    track_width = params['track_width']\n",
    "    distance_from_center = params['distance_from_center']\n",
    "    steering = abs(params['steering_angle'])\n",
    "    direction_stearing=params['steering_angle']\n",
    "    speed = params['speed']\n",
    "    steps = params['steps']\n",
    "    progress = params['progress']\n",
    "    all_wheels_on_track = params['all_wheels_on_track']\n",
    "    ABS_STEERING_THRESHOLD = 15\n",
    "    SPEED_TRESHOLD = 5\n",
    "    TOTAL_NUM_STEPS = 85\n",
    "    \n",
    "    # Read input variables\n",
    "    waypoints = params['waypoints']\n",
    "    closest_waypoints = params['closest_waypoints']\n",
    "    heading = params['heading']\n",
    "    \n",
    "    reward = 1.0\n",
    "        \n",
    "    if progress == 100:\n",
    "        reward += 100\n",
    "    \n",
    "    # Calculate the direction of the center line based on the closest waypoints\n",
    "    next_point = waypoints[closest_waypoints[1]]\n",
    "    prev_point = waypoints[closest_waypoints[0]]\n",
    "    \n",
    "    # Calculate the direction in radius, arctan2(dy, dx), the result is (-pi, pi) in radians\n",
    "    track_direction = math.atan2(next_point[1] - prev_point[1], next_point[0] - prev_point[0]) \n",
    "    \n",
    "    # Convert to degree\n",
    "    track_direction = math.degrees(track_direction)\n",
    "    \n",
    "    # Calculate the difference between the track direction and the heading direction of the car\n",
    "    direction_diff = abs(track_direction - heading)\n",
    "    \n",
    "    # Penalize the reward if the difference is too large\n",
    "    DIRECTION_THRESHOLD = 10.0\n",
    "    \n",
    "    malus=1\n",
    "    \n",
    "    if direction_diff > DIRECTION_THRESHOLD:\n",
    "        malus=1-(direction_diff/50)\n",
    "        if malus<0 or malus>1:\n",
    "            malus = 0\n",
    "        reward *= malus\n",
    "    \n",
    "    return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Source- [Medium- Sarah Lueck](https://medium.com/axel-springer-tech/how-to-win-aws-deepracer-ce15454f594a)__\n",
    "\n",
    "Selecting the top reward functions by the author. You can learn more by clicking on the link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def reward_function(params):\n",
    "\n",
    "    # Read input parameters\n",
    "    track_width = params['track_width']\n",
    "    distance_from_center = params['distance_from_center']\n",
    "    all_wheels_on_track = params['all_wheels_on_track']\n",
    "    is_left_of_center = params['is_left_of_center']\n",
    "    steering_angle = params['steering_angle']\n",
    "    speed = params['speed']\n",
    "    \n",
    "    if is_left_of_center == True:\n",
    "        distance_from_center *= -1\n",
    "\n",
    "    # implementation of reward function for distance from center\n",
    "    reward = (1 / (math.sqrt(2 * math.pi * (track_width*2/15) ** 2)) * math.exp(-((\n",
    "            distance_from_center + track_width/20) ** 2 / (4 * track_width*2/15) ** 2))) *(track_width*1/3)\n",
    "    \n",
    "    if not all_wheels_on_track:\n",
    "        reward = 1e-3\n",
    "\n",
    "    # implementation of reward function for steering angle\n",
    "    STEERING_THRESHOLD = 14.4\n",
    "    \n",
    "    if abs(steering_angle) < STEERING_THRESHOLD:\n",
    "        steering_reward = math.sqrt(- (8 ** 2 + steering_angle ** 2) + math.sqrt(4 * 8 ** 2 * steering_angle ** 2 + (12 ** 2) ** 2) ) / 10\n",
    "    else:\n",
    "        steering_reward = 0\n",
    "\n",
    "    # aditional reward if the car is not steering too much\n",
    "    reward *= steering_reward\n",
    "\n",
    "    # reward for the car taking fast actions (speed is in m/s)\n",
    "    reward *= math.sin(speed/math.pi * 5/6)\n",
    "    \n",
    "    # same reward for going slow with greater steering angle then going fast straight ahead \n",
    "    reward *= math.sin(0.4949 * (0.475 * (speed - 1.5241) + 0.5111 * steering_angle ** 2))\n",
    "\n",
    "    return float(reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Source- [Github- VilemR/AWS_DeepRacer](https://github.com/VilemR/AWS_DeepRacer)__\n",
    "\n",
    "Learn more by clicking on the link"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
