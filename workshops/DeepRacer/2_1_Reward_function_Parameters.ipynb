{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep dive into the reward function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Definition of the Reward function:__<br>\n",
    "A reward function describes immediate feedback (as a score for reward or penalty) when the vehicle takes an action to move from a given position on the track to a new position. Its purpose is to encourage the vehicle to make moves along the track to reach its destination quickly. The model training process will attempt to find a policy which maximizes the average total reward the vehicle experiences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__At Colaberry we have a dedicated course on [Python for Data Scientists](https://refactored.ai/course/python-for-data-scientists/) which we would recommend you to go through in case you would like to learn about coding in python as the reward function requires you to write code in Python programming language__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reward function Parameters/Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AWS DeepRacer reward function takes a dictionary object as the input.<br>\n",
    "Example of how the reward function looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function(params) :\n",
    "    \n",
    "    reward = ...\n",
    "\n",
    "    return float(reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us take a look at the parameters(inputs) the reward fuction can take.<br>\n",
    "The params dictionary object contains the following key-value pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"all_wheels_on_track\": Boolean,        # flag to indicate if the agent is on the track\n",
    "    \"x\": float,                            # agent's x-coordinate in meters\n",
    "    \"y\": float,                            # agent's y-coordinate in meters\n",
    "    \"closest_objects\": [int, int],         # zero-based indices of the two closest objects to the agent's current position of (x, y).\n",
    "    \"closest_waypoints\": [int, int],       # indices of the two nearest waypoints.\n",
    "    \"distance_from_center\": float,         # distance in meters from the track center \n",
    "    \"is_crashed\": Boolean,                 # Boolean flag to indicate whether the agent has crashed.\n",
    "    \"is_left_of_center\": Boolean,          # Flag to indicate if the agent is on the left side to the track center or not. \n",
    "    \"is_offtrack\": Boolean,                # Boolean flag to indicate whether the agent has gone off track.\n",
    "    \"is_reversed\": Boolean,                # flag to indicate if the agent is driving clockwise (True) or counter clockwise (False).\n",
    "    \"heading\": float,                      # agent's yaw in degrees\n",
    "    \"objects_distance\": [float, ],         # list of the objects' distances in meters between 0 and track_length in relation to the starting line.\n",
    "    \"objects_heading\": [float, ],          # list of the objects' headings in degrees between -180 and 180.\n",
    "    \"objects_left_of_center\": [Boolean, ], # list of Boolean flags indicating whether elements' objects are left of the center (True) or not (False).\n",
    "    \"objects_location\": [(float, float),], # list of object locations [(x,y), ...].\n",
    "    \"objects_speed\": [float, ],            # list of the objects' speeds in meters per second.\n",
    "    \"progress\": float,                     # percentage of track completed\n",
    "    \"speed\": float,                        # agent's speed in meters per second (m/s)\n",
    "    \"steering_angle\": float,               # agent's steering angle in degrees\n",
    "    \"steps\": int,                          # number steps completed\n",
    "    \"track_length\": float,                 # track length in meters.\n",
    "    \"track_width\": float,                  # width of the track\n",
    "    \"waypoints\": [(float, float), ]        # list of (x,y) as milestones along the track center\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A more detailed technical reference of the input parameters is as follows__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Parameters for the Reward function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Parameter:\n",
    "\n",
    "__all_wheels_on_track__\n",
    "\n",
    "__Type__: Boolean\n",
    "\n",
    "__Range__: (True:False)\n",
    "\n",
    "A Boolean flag to indicate whether the agent is on-track or off-track. It's off-track (False) if any of its wheels are outside of the track borders. It's on-track (True) if all of the wheels are inside the two track borders. The following illustration shows that the agent is on-track."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/deepracer-reward-function-input-all_wheels_on_track-true.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following illustration shows that the agent is off-track.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/deepracer-reward-function-input-all_wheels_on_track-false.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: A reward function using the all_wheels_on_track parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "define reward_function(params):\n",
    "    #############################################################################\n",
    "    '''\n",
    "    Example of using all_wheels_on_track and speed\n",
    "    '''\n",
    "\n",
    "    # Read input variables\n",
    "    all_wheels_on_track = params['all_wheels_on_track']\n",
    "    speed = params['speed']\n",
    "\n",
    "    # Set the speed threshold based your action space \n",
    "    SPEED_THRESHOLD = 1.0 \n",
    "\n",
    "    if not all_wheels_on_track:\n",
    "        # Penalize if the car goes off track\n",
    "        reward = 1e-3\n",
    "    elif speed < SPEED_THRESHOLD:\n",
    "        # Penalize if the car goes too slow\n",
    "        reward = 0.5\n",
    "    else:\n",
    "        # High reward if the car stays on track and goes fast\n",
    "        reward = 1.0\n",
    "\n",
    "    return reward`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Paramaters:\n",
    "    \n",
    "__waypoints__\n",
    "\n",
    "__Type__: list of [float, float]\n",
    "\n",
    "__Range__: [[$x_{w,0}$,$y_{w,0}$] â€¦ [$x_{w,Max-1}$, $y_{w,Max-1}$]]\n",
    "\n",
    "An ordered list of track-dependent `Max` milestones along the track center. Each milestone is described by a coordinate of ($x_{w,i}$, $y_{w,i}$). For a looped track, the first and last waypoints are the same. For a straight or other non-looped track, the first and last waypoints are different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/deepracer-reward-function-input-waypoints.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: A reward function using the waypoints parameter was used in the __closest_waypoints__ example below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Parameter:\n",
    "\n",
    "__closest_waypoints__\n",
    "\n",
    "__Type__: [int, int]\n",
    "\n",
    "__Range__: [(0:Max-1),(1:Max-1)]\n",
    "\n",
    "The zero-based indices of the two neighboring waypoints closest to the agent's current position of (x, y). The distance is measured by the Euclidean distance from the center of the agent. The first element refers to the closest waypoint behind the agent and the second element refers the closest waypoint in front of the agent. Max is the length of the waypoints list. In the illustration shown in waypoints, the closest_waypoints would be [16, 17].\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/deepracer-reward-function-input-waypoints.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example__: A reward function using the closest_waypoints parameter.\n",
    "\n",
    "The following example reward function demonstrates how to use waypoints and closest_waypoints as well as heading to calculate immediate rewards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function(params):\n",
    "    ###############################################################################\n",
    "    '''\n",
    "    Example of using waypoints and heading to make the car in the right direction\n",
    "    '''\n",
    "\n",
    "    import math\n",
    "\n",
    "    # Read input variables\n",
    "    waypoints = params['waypoints']\n",
    "    closest_waypoints = params['closest_waypoints']\n",
    "    heading = params['heading']\n",
    "\n",
    "    # Initialize the reward with typical value \n",
    "    reward = 1.0\n",
    "\n",
    "    # Calculate the direction of the center line based on the closest waypoints\n",
    "    next_point = waypoints[closest_waypoints[1]]\n",
    "    prev_point = waypoints[closest_waypoints[0]]\n",
    "\n",
    "    # Calculate the direction in radius, arctan2(dy, dx), the result is (-pi, pi) in radians\n",
    "    track_direction = math.atan2(next_point[1] - prev_point[1], next_point[0] - prev_point[0]) \n",
    "    # Convert to degree\n",
    "    track_direction = math.degrees(track_direction)\n",
    "\n",
    "    # Calculate the difference between the track direction and the heading direction of the car\n",
    "    direction_diff = abs(track_direction - heading)\n",
    "    if direction_diff > 180:\n",
    "        direction_diff = 360 - direction_diff\n",
    "\n",
    "    # Penalize the reward if the difference is too large\n",
    "    DIRECTION_THRESHOLD = 10.0\n",
    "    if direction_diff > DIRECTION_THRESHOLD:\n",
    "        reward *= 0.5\n",
    "\n",
    "    return reward\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Parameters:\n",
    "    \n",
    "__heading__\n",
    "\n",
    "__Type__: float\n",
    "\n",
    "__Range__: -180:+180\n",
    "\n",
    "Heading direction, in degrees, of the agent with respect to the x-axis of the coordinate system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/deepracer-reward-function-input-heading.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: A reward function using the heading parameter can be seen in the __closest_waypoints__ example above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Parameter:\n",
    "\n",
    "__closest_objects__\n",
    "\n",
    "__Type__: [int, int]\n",
    "\n",
    "__Range__: [(0:len(object_locations)-1), (0:len(object_locations)-1]\n",
    "\n",
    "The zero-based indices of the two closest objects to the agent's current position of (x, y). The first index refers to the closest object behind the agent, and the second index refers to the closest object in front of the agent. If there is only one object, both indices are 0.\n",
    "\n",
    "__Note__: This is primarily used for the object detection race in the AWS DeepRacer. For time trial race this can be ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Parameter:\n",
    "\n",
    "__distance_from_center__\n",
    "\n",
    "__Type__: float\n",
    "\n",
    "__Range__: 0:~track_width/2\n",
    "\n",
    "Displacement, in meters, between the agent center and the track center. The observable maximum displacement occurs when any of the agent's wheels are outside a track border and, depending on the width of the track border, can be slightly smaller or larger than half the track_width."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/deepracer-reward-function-input-distance_from_center.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: A reward function using the distance_from_center parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function(params):\n",
    "    #################################################################################\n",
    "    '''\n",
    "    Example of using distance from the center \n",
    "    ''' \n",
    "\n",
    "    # Read input variable\n",
    "    track_width = params['track_width']\n",
    "    distance_from_center = params['distance_from_center']\n",
    "\n",
    "    # Penalize if the car is too far away from the center\n",
    "    marker_1 = 0.1 * track_width\n",
    "    marker_2 = 0.5 * track_width\n",
    "\n",
    "    if distance_from_center <= marker_1:\n",
    "        reward = 1.0\n",
    "    elif distance_from_center <= marker_2:\n",
    "        reward = 0.5\n",
    "    else:\n",
    "        reward = 1e-3  # likely crashed/ close to off track\n",
    "\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Paramater:\n",
    "\n",
    "__is_crashed__\n",
    "\n",
    "__Type__: Boolean\n",
    "\n",
    "__Range__: (True:False)\n",
    "\n",
    "A Boolean flag to indicate whether the agent has crashed into another object (True) or not (False) as a termination status."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Paramater:\n",
    "\n",
    "__is_left_of_center__\n",
    "\n",
    "__Type__: Boolean\n",
    "\n",
    "__Range__: (True : False)\n",
    "\n",
    "A Boolean flag to indicate if the agent is on the left side to the track center (True) or on the right side (False)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Paramater:\n",
    "\n",
    "__is_offtrack__\n",
    "\n",
    "__Type__: Boolean\n",
    "\n",
    "__Range__: (True:False)\n",
    "\n",
    "A Boolean flag to indicate whether the agent has off track (True) or not (False) as a termination status."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Paramater:\n",
    "\n",
    "__is_reversed__\n",
    "\n",
    "__Type__: Boolean\n",
    "\n",
    "__Range__: (True:False)\n",
    "\n",
    "A Boolean flag to indicate if the agent is driving on clock-wise (True) or counter clock-wise (False).\n",
    "\n",
    "It's used when you enable direction change for each episode. An episode is a period in which the vehicle starts from a given starting point and ends up completing the track or going off the track."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Paramater:\n",
    "\n",
    "__objects_distance__\n",
    "\n",
    "__Type__: [float, â€¦ ]\n",
    "\n",
    "__Range__: [(0:track_length), â€¦ ]\n",
    "\n",
    "A list of the distances between objects in the environment in relation to the starting line. The $i_{th}$ element measures the distance in meters between the $i_{th}$ object and the starting line along the track center line.\n",
    "\n",
    "To index the distance between a single object and the agent, use:\n",
    "\n",
    "`abs(params[\"objects_distance\"][index] - (params[\"progress\"]/100.0)*params[\"track_length\"])`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/objects-distance-diagram.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Note__\n",
    "\n",
    "abs | (var1) - (var2)| = how close the car is to an object, WHEN var1 = [\"objects_distance\"][index] and var2 = params[\"progress\"]*params[\"track_length\"]\n",
    "\n",
    "To get an index of the closest object in front of the vehicle and the closest object behind the vehicle, use the \"closest_objects\" parameter.\n",
    "\n",
    "\n",
    "* This is primarily used for the object detection race in the AWS DeepRacer. For time trial race this can be ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Parameter:\n",
    "\n",
    "__objects_heading__\n",
    "\n",
    "__Type__: [float, â€¦ ]\n",
    "\n",
    "__Range__: [(-180:180), â€¦ ]\n",
    "\n",
    "List of the headings of objects in degrees. The $i_{th}$ element measures the heading of the $i_{th}$ object. For stationary objects, their headings are 0. For a bot vehicle, the corresponding element's value is the vehicle's heading angle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Parameter:\n",
    "\n",
    "__objects_left_of_center__\n",
    "\n",
    "__Type__: [Boolean, â€¦ ]\n",
    "\n",
    "__Range__: [True|False, â€¦ ]\n",
    "\n",
    "List of Boolean flags. The $i_{th}$ element value indicates whether the $i_{th}$ object is to the left (True) or right (False) side of the track center."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Parameter:\n",
    "\n",
    "__objects_location__\n",
    "\n",
    "__Type__: [(x,y), ...]\n",
    "\n",
    "__Range__: [(0:N,0:N), ...]\n",
    "\n",
    "List of all object locations, each location is a tuple of (x, y).\n",
    "\n",
    "The size of the list equals the number of objects on the track. Note the object could be the stationary obstacles, moving bot vehicles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Parameter:\n",
    "\n",
    "__objects_speed__\n",
    "\n",
    "__Type__: [float, â€¦ ]\n",
    "\n",
    "__Range__: [(0:12.0), â€¦ ]\n",
    "\n",
    "List of speeds (meters per second) for the objects on the track. For stationary objects, their speeds are 0. For a bot vehicle, the value is the speed you set in training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Parameter:\n",
    "\n",
    "__progress__\n",
    "\n",
    "__Type__: float\n",
    "\n",
    "__Range__: 0:100\n",
    "\n",
    "Percentage of track completed.\n",
    "\n",
    "Example: A reward function using the progress parameter is shared below in the _steps_ example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Parameters:\n",
    "    \n",
    "__speed__\n",
    "\n",
    "__Type__: float\n",
    "\n",
    "__Range__: 0.0:5.0\n",
    "\n",
    "The observed speed of the agent, in meters per second (m/s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/deepracer-reward-function-input-speed.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: A reward function using the speed parameter was the initial __all_wheels_on_track__ example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Parameters:\n",
    "\n",
    "__steering_angle__\n",
    "\n",
    "__Type__: float\n",
    "\n",
    "__Range__: -30:30\n",
    "\n",
    "Steering angle, in degrees, of the front wheels from the center line of the agent. The negative sign (-) means steering to the right and the positive (+) sign means steering to the left. The agent center line is not necessarily parallel with the track center line as is shown in the following illustration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/deepracer-reward-function-steering.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: A reward function using the steering_angle parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function(params):\n",
    "    '''\n",
    "    Example of using steering angle\n",
    "    '''\n",
    "\n",
    "    # Read input variable\n",
    "    steering = abs(params['steering_angle']) # We don't care whether it is left or right steering\n",
    "\n",
    "    # Initialize the reward with typical value \n",
    "    reward = 1.0\n",
    "\n",
    "    # Penalize if car steer too much to prevent zigzag\n",
    "    STEERING_THRESHOLD = 20.0\n",
    "    if steering > ABS_STEERING_THRESHOLD:\n",
    "        reward *= 0.8\n",
    "\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Parameter:\n",
    "\n",
    "__steps__\n",
    "\n",
    "__Type__: int\n",
    "\n",
    "__Range__: 0:Nstep\n",
    "\n",
    "Number of steps completed. A step corresponds to an action taken by the agent following the current policy.\n",
    "\n",
    "Example: A reward function using the steps parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function(params):\n",
    "    #############################################################################\n",
    "    '''\n",
    "    Example of using steps and progress\n",
    "    '''\n",
    "\n",
    "    # Read input variable\n",
    "    steps = params['steps']\n",
    "    progress = params['progress']\n",
    "    \n",
    "    # Total num of steps we want the car to finish the lap, it will vary depends on the track length\n",
    "    TOTAL_NUM_STEPS = 300\n",
    "\n",
    "    # Initialize the reward with typical value \n",
    "    reward = 1.0\n",
    "\n",
    "    # Give additional reward if the car pass every 100 steps faster than expected \n",
    "    if (steps % 100) == 0 and progress > (steps / TOTAL_NUM_STEPS) * 100 :\n",
    "        reward += 10.0\n",
    "\n",
    "    return reward\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Paramater:\n",
    "    \n",
    "__track_length__\n",
    "\n",
    "__Type__: float\n",
    "\n",
    "__Range__: [0:Lmax]\n",
    "\n",
    "The track length in meters. Lmax is track-dependent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Parameter:\n",
    "\n",
    "__track_width__\n",
    "\n",
    "__Type__: float\n",
    "\n",
    "__Range__: 0:Dtrack\n",
    "\n",
    "Track width in meters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/deepracer-reward-function-input-track_width.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: A reward function using the track_width parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function(params):\n",
    "    #############################################################################\n",
    "    '''\n",
    "    Example of using track width\n",
    "    '''\n",
    "\n",
    "    # Read input variable\n",
    "    track_width = params['track_width']\n",
    "    distance_from_center = params['distance_from_center']\n",
    "\n",
    "    # Calculate the distance from each border\n",
    "    distance_from_border = 0.5 * track_width - distance_from_center\n",
    "\n",
    "    # Reward higher if the car stays inside the track borders\n",
    "    if distance_from_border >= 0.05:\n",
    "        reward *= 1.0\n",
    "    else:\n",
    "        reward = 1e-3 # Low reward if too close to the border or goes off the track\n",
    "\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Parameters:\n",
    "\n",
    "__x, y__\n",
    "\n",
    "__Type__: float\n",
    "\n",
    "__Range__: 0:N\n",
    "\n",
    "Location, in meters, of the agent center along the x and y axes, of the simulated environment containing the track. The origin is at the lower-left corner of the simulated environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/deepracer-reward-function-input-x-y.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A quick recap of the AWS Deepracer and its functioning(Basics, paramaters and terminologies) can be found in nice interactive visualizations by on this [link](https://d2k9g1efyej86q.cloudfront.net/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
