{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Tutorial on Tensorflow Eager execution\n",
    "\n",
    "\n",
    "TensorFlow eager execution is an new addition to Google's TensorFlow framework. TensorFlow is a widely used framework for training and deploying deep learning models. Many topics covered in this tutorial are from the official TensorFlow website itself, I have tried to add a few points here and there that I found along the way as I adapted to this nuances of the framework. Eager execution is contentious since, for now, it trades speed for convenience. For some this tutorial might be very useful and for others it might be a rehash of the TensorFlow documentation hence I have tried to add links to the source material where ever I could to make it worth your while. \n",
    "\n",
    ". Previously, TensorFlow utilized a graph approach to constructing deep learning models where a network graph had to be coded up and a session had to be created and run. While the session mode in TensorFlow provides well optimized tools the eager mode is more suited for quick prototyping. We will be using TensorFlow 2.0 below for all the examples. The eager execution mode is available from tensorFlow 1.7+.\n",
    "\n",
    "Let us look at a simple example. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T08:33:11.265620Z",
     "start_time": "2020-02-01T08:33:05.980072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "# checking the version of tensorflow\n",
    "print(tf.__version__) \n",
    "\n",
    "\n",
    "# In TensorFlow 2.0 this is the way\n",
    "# to activate eager execution mode\n",
    "# and ONLY this way. \n",
    "tf.executing_eagerly()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T08:44:27.426503Z",
     "start_time": "2020-02-01T08:44:27.160041Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(1, 1) dtype=float32, numpy=array([[1.]], dtype=float32)>\n",
      " \n",
      " [1.] \n"
     ]
    }
   ],
   "source": [
    "# check if code is using gpu \n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# suppose we want to print a variable\n",
    "dummy = tf.Variable([[1.0]])\n",
    "dummy_numpy = dummy[0].numpy()\n",
    "\n",
    "print(dummy)\n",
    "print(\" \\n {} \".format(dummy_numpy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above block of code multiple things are happening so lets go over. It is always important to check which device TensorFlow is using to execute your code. In our case, we have wanted to ensure that it will use a local GPU to perform the calculations hence we placed the line below identify which device was used.\n",
    "\n",
    "```python \n",
    "# check if code is using gpu \n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "```\n",
    "\n",
    "The result was \n",
    "```python \n",
    "Executing op DestroyResourceOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
    "\n",
    "```\n",
    "As you can see, in the end it states that GPU:0 was used hence we can be sure that the GPU was used for computation.\n",
    "\n",
    "If you want to force TensorFlow to use a certain device, it is possible to do so using \n",
    "\n",
    "```python\n",
    "\n",
    "with tf.device(\"CPU:0\"):\n",
    "\n",
    "```\n",
    "In the above code, any code within the with statement will be executed by the CPU device rather than the GPU device. \n",
    "\n",
    "Now onto the core difference. In TensorFlow's graph mode statements like \n",
    "\n",
    "```python\n",
    "dummy = tf.Variable([[1.0]])\n",
    "print(dummy)\n",
    "```\n",
    "would not be possible. One would require a session.run() command to execute the above statement. Eager execution makes it easy to output the value of the tensor and more over it allows us to convert a tensor to a numpy value and tensor values to numpy values. \n",
    "\n",
    "Take for example\n",
    "\n",
    "```python \n",
    "dummy_np = np.array([10])\n",
    "tensor = tf.multiply(dummy_np, 2)\n",
    "print(\"Value of tensor {} \\ntype of tensor {}\" .format(tensor, type(tensor))) \n",
    "\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T08:53:37.325104Z",
     "start_time": "2020-02-01T08:53:37.308512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of tensor [20] \n",
      "type of tensor <class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "# execute the code below to see the result \n",
    "\n",
    "dummy_np = np.array([10])\n",
    "tensor = tf.multiply(dummy_np, 2)\n",
    "print(\"Value of tensor {} \\ntype of tensor {}\" .format(tensor, type(tensor))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-01T08:53:41.955648Z",
     "start_time": "2020-02-01T08:53:41.932703Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=166, shape=(1,), dtype=int32, numpy=array([20])>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": true,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
